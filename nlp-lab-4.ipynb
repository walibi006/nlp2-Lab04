{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction to Natural Language Processing 2 Lab04\n","Authors:\n","- Jonathan Poelger\n","- Ethan Machavoine\n","- Aurelien Rouxel"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["#!pip install bertopic\n","#!pip install -U accelerate\n","#!pip install evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:10:14.684489Z","iopub.status.busy":"2023-06-19T11:10:14.684115Z","iopub.status.idle":"2023-06-19T11:10:48.599285Z","shell.execute_reply":"2023-06-19T11:10:48.598297Z","shell.execute_reply.started":"2023-06-19T11:10:14.684454Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from datasets import load_dataset\n","from bertopic import BERTopic\n","from umap import UMAP\n","from transformers import AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\n","import evaluate\n","from transformers import AutoModelForSequenceClassification"]},{"cell_type":"markdown","metadata":{},"source":["# Introduction"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Loading both of the possible datasets\n","hate = load_dataset(\"tweet_eval\", \"hate\")\n","offensive = load_dataset(\"tweet_eval\", \"offensive\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:10:54.803911Z","iopub.status.busy":"2023-06-19T11:10:54.802975Z","iopub.status.idle":"2023-06-19T11:10:55.071962Z","shell.execute_reply":"2023-06-19T11:10:55.070828Z","shell.execute_reply.started":"2023-06-19T11:10:54.803854Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["A woman who you fucked multiple times saying yo dick small is a compliment you know u hit that spot ðŸ˜Ž \n","\n","@user @user real talk do you have eyes or were they gouged out by a rapefugee? \n","\n","your girlfriend lookin at me like a groupie in this bitch! \n","\n","I AM NOT GOING AFTER YOUR EX BF YOU LIEING SACK OF SHIT ! I'm done with you dude that's why I dumped your ass cause your a lieing ðŸ˜‚ðŸ˜¡ bitch \n","\n","Send home migrants not in need of protection, Peter Dutton tells UN, HEY DUTTON HOW ABOUT THE ONES THAT HAVE STAYED AND NOT LEFT THE COUNTRY WHEN THEY SHOULD OVERSTAYERS ? WHY DONT YOU GO AND ROUND ALL THEM UP ? \n","\n","Cory Booker and Kamala Harris competing for Most Hysterical Woman at the Kavanaugh hearings, Coulter hilariously tweeted.And yes, liberals immediately got triggered on Twitter, saying her joke was offensive. To them we say, suck it up, snowflakes. \n","\n","Should have let the Libyan Manchester bomber rot in his own country. How many more mass murderers did the Royal Navy import to Britain? How many more terrorists do the NGO's rescue from international waters? #RefugeesNotWelcome \n","\n","This account was temporarily inactive due to an irrational woman reporting us to Twitter. What a lack of judgement, shocking. #YesAllMen \n","\n","listen... i love lil b but i would not fuck with dej loaf at all. she prob got poison up in her nail polish like that bitch from holes \n","\n","@user @user keep calling her a bitch and a whore dude real grown up. \n","\n"]}],"source":["#Exemples of 'hate' dataset\n","i = 0\n","printed = 0\n","while printed < 10:\n","    if hate[\"train\"][\"label\"][i] == 1 :\n","        print(hate[\"train\"][\"text\"][i], \"\\n\")\n","        printed += 1\n","    i+=1\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:10:55.073591Z","iopub.status.busy":"2023-06-19T11:10:55.073250Z","iopub.status.idle":"2023-06-19T11:10:55.473335Z","shell.execute_reply":"2023-06-19T11:10:55.472152Z","shell.execute_reply.started":"2023-06-19T11:10:55.073559Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["@user Eight years the republicans denied obamaâ€™s picks. Breitbarters outrage is as phony as their fake president. \n","\n","@user She has become a parody unto herself? She has certainly taken some heat for being such an....well idiot. Could be optic too  Who know with Liberals  They're all optics.  No substance \n","\n","@user Your looking more like a plant #maga #walkaway \n","\n","@user Antifa would burn a Conservatives house down and CNN would be there lighting the torches &amp; throwing gas on the flames. \n","\n","@user They cite Jones being banned for violating Twitter's ToS. There are blue checkmarks spewing the same, if not worse, kind of shit. If you are going to play the anyone can get banned\"\" card. Shouldn't these people also receive bans and suspensions? #VerifiedHate\"\" \n","\n","@user also shitbiscuit stole most of the Tempe girls u can't blame that on me.. \n","\n","@user @user Well, see, if I start talking at Dana about sensible gun control laws and she ignores me (or calls me a tragedy dry-humping whore\"\" as she did @user then we aren't having a conversation. I'm just talking into the void.\"\" \n","\n","@user All you do is lie. All congress does us lie.  MAGA. \n","\n","@user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user @user He also clarified that there is the water birth when we are physically born. Then there is the spiritual birth which is obviously when we spiritually die to our sinful flesh and be reborn sinless after being cleansed by His blood at salvation when our sin debt is paid! Praise God \n","\n","@user @user Why are you wasting time replying on twitter (trolling) on behalf of people making under that amount?  Seems like someone is just a propaganda pusher...or likes gloating to other #MAGA's that they got screwed by Trump. \n","\n"]}],"source":["#Exemples of 'offensive' dataset\n","i = 0\n","printed = 0\n","while printed < 10:\n","    if offensive[\"train\"][\"label\"][i] == 1 :\n","        print(offensive[\"train\"][\"text\"][i], \"\\n\")\n","        printed += 1\n","    i+=1"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset\n","\n","After analizing the two datasets, it seems that the 'hate' dataset in more about insults and defamation, while 'offensive' is way more political and about people arguing.\\\n","They also both have a similar amount of exemples (12970 and 14100), so the matter of amount of data isn't relevant to choose.\\\n","Something relevant is the legislation of these datasets. The 'hate' dataset is unde the Creative Commons bCC-BY-NC-4.0 license, which makes it, among other things, not usable for commercial purposes.\\\n","The 'offensive' dataset isn't under any other legislations than the twitter's terms of services, so we can use it for commercial purposes.\\\n","\n","We will then choose the 'offensive' dataset."]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating the dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:10:55.475465Z","iopub.status.busy":"2023-06-19T11:10:55.475070Z","iopub.status.idle":"2023-06-19T11:10:55.505070Z","shell.execute_reply":"2023-06-19T11:10:55.503735Z","shell.execute_reply.started":"2023-06-19T11:10:55.475409Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train: 66.93 % of 'offensive' tweets\n","val: 65.33 % of 'offensive' tweets\n","test: 72.09 % of 'offensive' tweets\n"]}],"source":["#Class repartition in the dataset splits\n","print(\"train:\", round(offensive[\"train\"][\"label\"].count(0) / len(offensive[\"train\"][\"label\"]) * 100, 2), \"% of 'offensive' tweets\")\n","print(\"val:\", round(offensive[\"validation\"][\"label\"].count(0) / len(offensive[\"validation\"][\"label\"]) * 100, 2), \"% of 'offensive' tweets\")\n","print(\"test:\", round(offensive[\"test\"][\"label\"].count(0) / len(offensive[\"test\"][\"label\"]) * 100, 2), \"% of 'offensive' tweets\")"]},{"cell_type":"markdown","metadata":{},"source":["- train: 66.93 % of 'offensive' tweets\n","- val  : 65.33 % of 'offensive' tweets\n","- test : 72.09 % of 'offensive' tweets"]},{"cell_type":"markdown","metadata":{},"source":["### Getting the topics"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:10:55.507875Z","iopub.status.busy":"2023-06-19T11:10:55.507087Z","iopub.status.idle":"2023-06-19T11:10:55.516954Z","shell.execute_reply":"2023-06-19T11:10:55.515394Z","shell.execute_reply.started":"2023-06-19T11:10:55.507837Z"},"trusted":true},"outputs":[],"source":["random_seed = 42\n","\"\"\"\n","Given a BERTopic umap model and a dataframe,\n","computes and prints the main topics\n","\"\"\"\n","def get_topics(umap_model, df):\n","    docs = df[\"train\"][\"text\"] + df[\"validation\"][\"text\"] + df[\"test\"][\"text\"]\n","    topic_model = BERTopic(umap_model=umap_model)\n","    topics, probs = topic_model.fit_transform(docs)\n","    ret = topic_model.get_topic_info()[0:5][\"Representation\"].tolist()\n","    for i in ret:\n","        print(i)\n","\n","umap_model = UMAP(n_neighbors=15, n_components=5, \n","                  min_dist=0.0, metric='cosine', random_state=42)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:10:55.519213Z","iopub.status.busy":"2023-06-19T11:10:55.518610Z","iopub.status.idle":"2023-06-19T11:11:55.008420Z","shell.execute_reply":"2023-06-19T11:11:55.007425Z","shell.execute_reply.started":"2023-06-19T11:10:55.519178Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0dc5ddc067ef4ebd90d166ae6f02578b","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"133f9fc26c31452c8135eb644e9933f0","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f062966b36245f38ff94b78edea95b5","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6ff423a34bb411aa559bb96b2dfb6c4","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bcbaaa77a4144c8bae721f4da3283d0","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"848614847c414d259794acd3ea1e8a9f","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e2f0bab9f58411cbf759b569d5203ba","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8c2dfe4639d428db41d74863a242c0e","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dddb99c64adc4c8982cf93afcf1d8337","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77e27b76db6d40eca5b6b00176836ba9","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"405c4fcf68c84dac924190ba89d22046","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4776546810de43d69612e0cf6a0d0e20","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da20e5e7611649dfa48efa5774016971","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ac3145557a2496eb5ff0a8e49cd2d60","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['to', 'the', 'is', 'and', 'you', 'of', 'he', 'she', 'are', 'user']\n","['right', 'user', 'wrong', 'you', 'correct', 'are', 'absolutely', 'it', 'what', 'should']\n","['liberals', 'user', 'they', 'are', 'all', 'their', 'liberal', 'that', 'dont', 'crazy']\n","['brexit', 'tories', 'labour', 'eu', 'housing', 'conservatives', 'uk', 'tory', 'the', 'party']\n","['nfl', 'football', 'he', 'game', 'team', 'league', 'is', 'his', 'him', 'season']\n"]}],"source":["#Topics of the wole dataset\n","get_topics(umap_model, offensive)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:11:55.012180Z","iopub.status.busy":"2023-06-19T11:11:55.010194Z","iopub.status.idle":"2023-06-19T11:12:11.703550Z","shell.execute_reply":"2023-06-19T11:12:11.702288Z","shell.execute_reply.started":"2023-06-19T11:11:55.012144Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b6240c09fbe42a288db62e52f9580a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc9dfa082e6540a7852a58812d67058f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5746eba168164a0ba3df3806fcb1d6c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['user', 'is', 'she', 'to', 'and', 'the', 'he', 'you', 'of', 'are']\n","['gun', 'control', 'the', 'laws', 'guns', 'to', 'user', 'in', 'of', 'that']\n","['antifa', 'user', 'the', 'fascist', 'to', 'and', 'of', 'they', 'are', 'in']\n","['maga', 'trump', 'the', 'walkaway', 'user', 'qanon', 'wwg1wga', 'and', 'to', 'for']\n","['liberals', 'are', 'user', 'all', 'they', 'liberal', 'the', 'of', 'and', 'to']\n"]}],"source":["#Topics of the flagged offensive tweets\n","get_topics(umap_model, offensive.filter(lambda example: example['label'] == 1))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:12:11.708254Z","iopub.status.busy":"2023-06-19T11:12:11.707808Z","iopub.status.idle":"2023-06-19T11:12:44.153461Z","shell.execute_reply":"2023-06-19T11:12:44.152276Z","shell.execute_reply.started":"2023-06-19T11:12:11.708215Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"977b62c4515d4bbabdcdfdefc98e93db","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14fb38e97b824d4aa56263bb87648b07","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aae913f036b94333bccfb596fed6b828","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['the', 'and', 'to', 'you', 'is', 'of', 'he', 'are', 'in', 'for']\n","['right', 'user', 'you', 'are', 'correct', 'what', 'wrong', 'it', 'he', 'absolutely']\n","['liberals', 'user', 'they', 'liberal', 'the', 'all', 'have', 'dont', 'their', 'to']\n","['kavanaugh', 'maga', 'judge', 'kavanaughs', 'ford', 'testify', 'to', 'feinstein', 'her', 'fbi']\n","['brexit', 'labour', 'conservatives', 'tories', 'housing', 'eu', 'the', 'uk', 'of', 'tory']\n"]}],"source":["#topics of the flagged neutral tweets\n","get_topics(umap_model, offensive.filter(lambda example: example['label'] == 0))"]},{"cell_type":"markdown","metadata":{},"source":["# Topics results\n","\n","### Most notable topics on the whole dataset :\n","- right, wrong, correct, should: people arguing\n","- liberals, conservatives, brexit, tories, eu, uk: politics\n","- crazy: most likely insulting, but can be used for emphasis (cf. \"it's crazy expensive\")\n","- nfl, football, team, league, game, season: sports\n","\n","### Most notable topics on the flagged offensive subset :\n","- gun, control, law: legislation around guns\n","- antifa, facsist: political extremes\n","- maga, trump, wwg1wga: Donald Trump and his political movement\n","- quanon:  American political conspiracy theory and political movement\n","- liberals: politics\n","\n","### Most notable topics on the not flagged offensive subset :\n","- right, wrong, correct, should: people arguing\n","- liberals, tory, brexit, eu, uk: UK politics\n","- maga, judge, kavanaught, feinstein: american politics\n","- labour, housing: people common issues \n","- fbi: american l federal law enforcement agency (widely used as a joke on social medias)\n","\n","As we can see, the flagged 'offensive' tweets are mostely about american politics (gun control, Trump, etc.), while the not offensives ones are also about UK, and people arguing about various issues. The 'offensive' subset is also about more sensitive contents and extremes. \n","\n","This could create a bias in the model towards american-related arguments and also politics in general for exemple. The exemples later will show these \"political\", \"US\" ans \"UK\" biases at work."]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate a model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:12:44.156189Z","iopub.status.busy":"2023-06-19T11:12:44.155719Z","iopub.status.idle":"2023-06-19T11:12:57.729121Z","shell.execute_reply":"2023-06-19T11:12:57.728045Z","shell.execute_reply.started":"2023-06-19T11:12:44.156154Z"},"trusted":true},"outputs":[],"source":["task='offensive'\n","MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n","\n","\"\"\"\n","Given a trainer containing a model and a dataset,\n","Computes and prints the metrics of the model\n","\"\"\"\n","def compute_metrics(trainer, dataset):\n","    predictions = trainer.predict(dataset[\"test\"])\n","    true_labels = dataset[\"test\"][\"label\"]\n","    predicted_labels = np.argmax(predictions.predictions, axis=1)\n","    accuracy = np.mean(predicted_labels == dataset[\"test\"][\"label\"])\n","    \n","    predicted_labels = list(predicted_labels)\n","    true_positives = 0\n","    false_positives = 0\n","    false_negatives = 0\n","    \n","    for i in range(len(true_labels)):\n","        true_positives += predicted_labels[i] == 1 and true_labels[i] == 1\n","        false_positives += predicted_labels[i] == 1 and true_labels[i] == 0\n","        false_negatives += predicted_labels[i] == 0 and true_labels[i] == 1\n","    \n","    precision = true_positives / (true_positives + false_positives)\n","    recall = true_positives / (true_positives + false_negatives)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","    \n","    print(\"Accuracy :\", accuracy)\n","    print(\"Precision:\", precision)\n","    print(\"Recall   :\", recall)\n","    print(\"F1-score :\", f1_score)\n","    return trainer, dataset\n","\n","\"\"\"\n","Given a model name,\n","Creates a tokenizer and returns the tokenized dataset, tokenizer and model name\n","\"\"\"\n","def load_data(checkpoint):\n","    raw_datasets = load_dataset(\"tweet_eval\", \"offensive\")\n","    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","    tokenized_datasets = raw_datasets.map(lambda example: tokenizer.__call__(example[\"text\"], truncation=True), batched=True)\n","    return tokenized_datasets, tokenizer, checkpoint\n","\n","\"\"\"\n","Given a tokenized dataset, tokenizer and a model name,\n","Creates a trainer and returns it as well as the dataset\n","\"\"\"\n","def create_model(tokenized_datasets, tokenizer, checkpoint ,num_train_epochs=1):\n","    training_args = TrainingArguments(\"test-trainer\", num_train_epochs=num_train_epochs, report_to=\"none\")\n","    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","    trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator= DataCollatorWithPadding(tokenizer=tokenizer),\n","    tokenizer=tokenizer,\n","    )\n","    return trainer, tokenized_datasets\n","\n","trainer, dataset = compute_metrics(*create_model(*load_data(MODEL)))"]},{"cell_type":"markdown","metadata":{},"source":["Accuracy : 0.8593023255813953\\\n","Precision: 0.7960199004975125\\\n","Recall   : 0.6666666666666666\\\n","F1-score : 0.7256235827664399"]},{"cell_type":"markdown","metadata":{},"source":["### Prediction failures analysis"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:12:57.731355Z","iopub.status.busy":"2023-06-19T11:12:57.730913Z","iopub.status.idle":"2023-06-19T11:13:00.576379Z","shell.execute_reply":"2023-06-19T11:13:00.574251Z","shell.execute_reply.started":"2023-06-19T11:12:57.731319Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\tfalse positive\n","@user I guess thatâ€™s where swamp ass originated\n","Are you fucking serious?\n","An American Tail really is one of the most underrated animations ever ever ever. Fuck I cried in this scene\n","@user @user Bull crap. You know she doesn't care.  She is trying to get attention for her Presidential run.  Do you see any other Senator giving nonsense?  Nope.\n","#Room25 is actually incredible, Noname is the shit, always has been,  and Iâ€™m seein her in like 5 days in Melbourne. Life is good. Have a nice day.\n","\n","\tfalse negative\n","#Liberals / #Democrats THIS is what you stand for. If not, then #WalkAway\n","#Liberals Are Reaching Peak Desperation To Call On #PhillipRuddock To Talk With #Turnbull To Convince Him To Help with #WentworthVotes 18 Sept 2018  @user #Auspol #LNP #NSWpol @user  @user @user #LNPMemes\n","#BREXIT deal HAS been reached - and will be unveiled at special summit in NOVEMBER, Has @user sold out the #UK to the eu??? She better have not or the @user are finished!! @user\n","#NoPasaran: Unity demo to oppose the far-right in #London â€“ #antifa #Oct13 â€” Enough is Enough!\n","#America  ... tear down that #Wall! #tcot #partisanship #Trump #thewall #Borderwall #liberty #civilsociety #think #Conservatives #Democrats #Progressives #liberals #Independent #libertarians #GOP #DNC #CriticalThinking\n"]}],"source":["#Get all the needed vectors of prediction and ground truth\n","preds = trainer.predict(dataset[\"test\"]).predictions\n","truth = dataset[\"test\"][\"label\"]\n","texts =  dataset[\"test\"][\"text\"]\n","labels = np.argmax(preds, axis=1)\n","\n","tp = []\n","tn = []\n","fp = []\n","fn = []\n","#Classify the predictions using confusion matrix \n","for i in range(len(preds)):\n","        if truth[i] == 0 and labels[i] == 0:\n","            tn.append((texts[i], max(preds[i])))\n","        elif truth[i] == 0 and labels[i] == 1:\n","            fp.append((texts[i], max(preds[i])))\n","        elif truth[i] == 1 and labels[i] == 0:\n","            fn.append((texts[i], max(preds[i])))\n","        elif truth[i] == 1 and labels[i] == 1:\n","            tp.append((texts[i], max(preds[i])))\n","\n","def takeSecond(elem):\n","    return elem[1]\n","tp.sort(key=takeSecond, reverse=True)\n","fp.sort(key=takeSecond, reverse=True)\n","tn.sort(key=takeSecond, reverse=True)\n","fn.sort(key=takeSecond, reverse=True)\n","\n","#Outputs the most wrong awnsers\n","print(\"\\tfalse positive\")\n","for i in range(5):\n","    print(fp[i][0])\n","\n","print(\"\\n\\tfalse negative\")\n","for i in range(5):\n","    print(fn[i][0])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### False positive\n","@user I guess thatâ€™s where swamp ass originated\n","\n","\n","Are you fucking serious?\n","\n","\n","An American Tail really is one of the most underrated animations ever ever ever. Fuck I cried in this scene\n","\n","\n","@user @user Bull crap. You know she doesn't care.  She is trying to get attention for her Presidential run. Do you see any other Senator giving nonsense?  Nope.\n","\n","\n","\\#Room25 is actually incredible, Noname is the shit, always has been, and Iâ€™m seein her in like 5 days in Melbourne. Life is good. Have a nice day.\n","\n","### Fasle negative\n","\\#Liberals / #Democrats THIS is what you stand for. If not, then #WalkAway\n","\n","\n","\\#Liberals Are Reaching Peak Desperation To Call On #PhillipRuddock To Talk With #Turnbull To Convince Him To Help with #WentworthVotes 18 Sept 2018  @user #Auspol #LNP #NSWpol @user  @user @user #LNPMemes\n","\n","\n","\\#BREXIT deal HAS been reached - and will be unveiled at special summit in NOVEMBER, Has @user sold out the #UK to the eu??? She better have not or the @user are finished!! @user\n","\n","\n","\\#NoPasaran: Unity demo to oppose the far-right in #London â€“ #antifa #Oct13 â€” Enough is Enough!\n","\n","\n","\\#America  ... tear down that #Wall! #tcot #partisanship #Trump #thewall #Borderwall #liberty #civilsociety #think #Conservatives #Democrats #Progressives #liberals #Independent #libertarians #GOP #DNC #CriticalThinking\n","\n","\n","### Possible issues and biases\n","The 5 most wrong awsners in the false positives all have a vulgar word within them, but that's the only common factor that could have them wrongly calssified. The \"US bias\" can have an impact on the comment about \"American Tail\" (a movie title), and the \"political bias\" can have an impact on the comment with the words 'Presidantial' and 'Senator'\n","\n","\n","The 5 most wrong awsners in the false negatives all have a lot of hashtags in them, some of them even in the middle of a sentense. The model may take them as separate words and so not link them with their context like it usually does. Also all of them are about UK politics, so the \"UK bias\" play a role in the classification\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:13:00.578328Z","iopub.status.busy":"2023-06-19T11:13:00.577859Z","iopub.status.idle":"2023-06-19T11:13:08.361142Z","shell.execute_reply":"2023-06-19T11:13:08.360138Z","shell.execute_reply.started":"2023-06-19T11:13:00.578287Z"},"trusted":true},"outputs":[],"source":["\n","\"\"\"\n","This code aims to load english tweets from the twitter database.\n","Unfortunately, while loading them isn't that much of an issue,\n","I couldn't find a way to properly pass them to the network.\n","\"\"\"\n","import json\n","\n","tweets = []\n","for i in range(30,60):\n","    with open('/kaggle/input/tweets/'+ str(i) +'.json') as f:\n","        for jsonObj in f:\n","            tweetDict = json.loads(jsonObj)\n","            if \"lang\" in tweetDict and tweetDict[\"lang\"] == 'en':\n","                tweets.append(tweetDict['text'])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Advantages of using a pre-trained transformer:\n","\n","- Better generalization and performance compared to naive Bayes, which relies on simple probabilities.\n","\n","- Transformers learns the relationships between words in a sentence, and context. This way, it can understand more complex language structures compared to Naive Bayes that takes each words one by one. It can also see dependencies between words very far away in the texts, and is in fact very good at it.\n","\n","- Pre-trained transformers can be fine-tuned with a few labeled data. This makes them more effective in scenarios where labeled data isn't easy to find. Naive Bayes requires a larger labeled dataset for training. It also gives it the ability to be quickly trained for new domains or problems.\n","\n","- Pre-trained transformers like BERT or GPT have shown very good results on natural language processing tasks. Naive Bayes have less good results in basically every domains. In fact, while Naive Bayes is limited to classification, Transformers can handle a wide range of problems\n","\n","- Pre-trained transformer models, with libraries like Hugging Face Transformers, are already easily available for wide range of problems. This accessibility and fast development make it generally a better choice over Naive Bayes which is harder to find and maintain."]},{"cell_type":"markdown","metadata":{},"source":["### Annotate data"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:13:08.362782Z","iopub.status.busy":"2023-06-19T11:13:08.362427Z","iopub.status.idle":"2023-06-19T11:13:08.368900Z","shell.execute_reply":"2023-06-19T11:13:08.367815Z","shell.execute_reply.started":"2023-06-19T11:13:08.362750Z"},"trusted":true},"outputs":[],"source":["def get_tweets():\n","    pass"]},{"cell_type":"markdown","metadata":{},"source":["### Labeling guidelines\n","\n","1. Offensive Class Definition:\n","\n","   The offensive class in this annotation guideline are tweets that contain offensive content. Offensive content is targeting directs a person, a group of people, an institution, or an idea and spreading misinformations, insults, hate speech, threats, or any other kind of objectively false and/or harmful information.\n","   \n","   The subject ranges from personal attributes to groups, such as race, gender, religion, ethnicity, sexual orientation, political view, appearance, personal preferences and opinions, etc.\n","   \n","   A negative comment isn't necessarily offensive. Information that is objectively and unmistakably true cannot be flagged as offensive, even if the recipient doesn't like what is said. More on that subject on the \"Ambiguous\" part.\n","   \n","   A comment that clearly isn't offensive will be treated as \"Neutral\" here. There will also be a \"Not annotable\" class\n","\n","2. Offense Examples:\n","   - _\"@user lemme tell ya bro, arab people are fucking terrorists\"_ => objectively false and targetting a group of person, spreading false and harmful informations towards them\n","   - _\"@user You so fat you have your own gravitational field\"_ => absolutely impossible and shaming a person's appearance\n","   - _\"I can't belive #wwg1wgaat is again promoting school shootings for the sake of it..... #guncontrol #Trump\"_ => misinformation about a political party \n","\n","3. Negative but not offensive comments (counterpart of above section):\n","    - _\"The latest attack has been revamped by Islamist extermists\"_\n","    - _\"@user, your extrem overweight is bad for your health and can causes multiple vascular diseases\"_\n","    \n","    => By stating only stating facts, not confusing words and ideas and being polite, The disscutions can be kept civil about any subjects and thus are not offensive.\n","    \n","    - _\"#wwg1wga is promoting gun rights in America while there is still school shootings on a regular basis. This is very illogical in my opinion and I think they souldn't do that for the sake of our childen's safety.\"_\n","    \n","    => One can voice their opinion and disagreeing without it being offensive. As above, stating facts and staying polite is a good way to state disagreement with an idea without it being offensive, even on serious and sensitive matters.\n","    \n","4. Ambiguous Cases:\n","   It is important to pay attention to ambiguous cases where the presence of offense may not be immediately evident. Subtle forms of offensive language, sarcasm, satire, or irony can be hard to juge as offensive or not. The annotators should consider the overall context, tone, and intent of the tweet when making judgments.\n","\n","5. Can't Tell / Not Annotable Class:\n","   When an exemple is too ambibuous, we can use the \"Can't tell / not annotable\" class. It is usefull as the annotator can be perplexed as how to classify borderline exemples.\n","   \n","6. Consistency:\n","   When considering different languages, cultures, and regional contexts, some exemples may be hard to classify. Offensive content can vary across languages and cultures, so annotators should be aware of potential cultural biases and understand the context of the specific language and culture being analyzed. For the sake of impartiality we need discussion among annotators, as well as multiple annotators labeling the same exemples. If disagreement on a label arises, deeper rescearch and disscutions will be made to ensure consistency in labeling."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-19T11:14:14.443888Z","iopub.status.busy":"2023-06-19T11:14:14.443448Z","iopub.status.idle":"2023-06-19T11:14:14.451301Z","shell.execute_reply":"2023-06-19T11:14:14.450304Z","shell.execute_reply.started":"2023-06-19T11:14:14.443833Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Given a list of tweets and possibly a number of target class to get,\n","Provides with and easy way to annotate the data\n","\"\"\"\n","def annotate(tweets, target_class = 50):\n","    dataset = []\n","    offensive = 0\n","    for tweet in tweets:\n","        print(tweet)\n","        label = input()\n","        dataset.append((tweet,label))\n","        if label == 1:\n","            offensive +=1\n","            if offensive == target_class:\n","                break\n","    return dataset"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
